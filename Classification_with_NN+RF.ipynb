{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7a10d1-b8c4-47f9-a06a-3c40cd5fa3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a96150-2cd6-4aba-984b-dc1cbcdd9ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"DDAM Project\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04586d53-1e60-43a0-be69-53ac8fb1a25a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c667b946-70a3-40e2-9ae9-1793b6cd1016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_boxscore = spark.read.csv(\"data/boxscore_clean/part-00000-9aabd889-393c-4f37-87d7-b56657fa2ef0-c000.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a36f25-27d8-46b3-bf90-9690b642a9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df_boxscore.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4deff412-2294-4577-8f33-74083ef3ef29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Renaming\n",
    "df_boxscore = df_boxscore.withColumnRenamed(\"pos_clean\", \"Position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0fb90f3-8be7-4004-9737-6e20d22a55a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- playerName: string (nullable = true)\n",
      " |-- game_id: integer (nullable = true)\n",
      " |-- teamName: string (nullable = true)\n",
      " |-- FG: integer (nullable = true)\n",
      " |-- FGA: integer (nullable = true)\n",
      " |-- 3P: integer (nullable = true)\n",
      " |-- 3PA: integer (nullable = true)\n",
      " |-- FT: integer (nullable = true)\n",
      " |-- FTA: integer (nullable = true)\n",
      " |-- ORB: integer (nullable = true)\n",
      " |-- DRB: integer (nullable = true)\n",
      " |-- TRB: integer (nullable = true)\n",
      " |-- AST: integer (nullable = true)\n",
      " |-- STL: integer (nullable = true)\n",
      " |-- BLK: integer (nullable = true)\n",
      " |-- TOV: integer (nullable = true)\n",
      " |-- PF: integer (nullable = true)\n",
      " |-- PTS: integer (nullable = true)\n",
      " |-- +/-: integer (nullable = true)\n",
      " |-- isStarter: integer (nullable = true)\n",
      " |-- seasonStartYear: integer (nullable = true)\n",
      " |-- isRegular: integer (nullable = true)\n",
      " |-- Ht: string (nullable = true)\n",
      " |-- Wt: double (nullable = true)\n",
      " |-- feet: double (nullable = true)\n",
      " |-- inches: string (nullable = true)\n",
      " |-- MP_seconds: integer (nullable = true)\n",
      " |-- Position: string (nullable = true)\n",
      " |-- TSP: double (nullable = true)\n",
      " |-- EFG: double (nullable = true)\n",
      " |-- TO_ratio: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_boxscore.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f3cf9-476c-4935-9176-3f55e487bb23",
   "metadata": {},
   "source": [
    "## Position one-hot-enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7a2be45-d808-4e9c-a877-ea35f5ae9cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Position\", outputCol=\"PosNum\", handleInvalid=\"skip\")\n",
    "\n",
    "df_boxscore = indexer.fit(df_boxscore).transform(df_boxscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009cbaf4-28f5-45c7-bc85-60b0975f34ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 11:54:51 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+--------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---------+---------------+---------+----+-----+------------------+------+----------+--------+-------------------+-------------------+-------------------+------+-------------+\n",
      "|        playerName|game_id|            teamName| FG|FGA| 3P|3PA| FT|FTA|ORB|DRB|TRB|AST|STL|BLK|TOV| PF|PTS|+/-|isStarter|seasonStartYear|isRegular|  Ht|   Wt|              feet|inches|MP_seconds|Position|                TSP|                EFG|           TO_ratio|PosNum|       PosVec|\n",
      "+------------------+-------+--------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---------+---------------+---------+----+-----+------------------+------+----------+--------+-------------------+-------------------+-------------------+------+-------------+\n",
      "|Corliss Williamson|      1|    Sacramento Kings|  7| 11|  0|  0|  0|  0|  1|  3|  4|  4|  1|  1|  4|  5| 14| -2|        1|           1996|        1|NULL|245.0|            200.66|  NULL|      2240|       F| 0.6363636363636364| 0.6363636363636364|0.21052631578947367|   1.0|(2,[1],[1.0])|\n",
      "|    Olden Polynice|      1|    Sacramento Kings|  0|  4|  0|  0|  1|  4|  2|  5|  7|  3|  1|  0|  4|  3|  1|-12|        1|           1996|        1|NULL|220.0|            210.82|  NULL|      1894|       C|0.08680555555555555|                0.0|0.31347962382445144|   2.0|    (2,[],[])|\n",
      "|Mahmoud Abdul-Rauf|      1|    Sacramento Kings|  7| 13|  1|  2|  2|  2|  0|  2|  2|  5|  1|  1|  2|  2| 17| -7|        1|           1996|        1|NULL|162.0|            185.42|  NULL|      1767|       G| 0.6123919308357348| 0.5769230769230769|0.09578544061302681|   0.0|(2,[0],[1.0])|\n",
      "|       Brian Grant|      1|    Sacramento Kings|  3| 11|  0|  0|  2|  2|  1|  5|  6|  0|  0|  2|  1|  2|  8| -7|        1|           1996|        1|NULL|254.0|            205.74|  NULL|      1513|       F|0.33670033670033667| 0.2727272727272727|0.07763975155279502|   1.0|(2,[1],[1.0])|\n",
      "|        Tyus Edney|      1|    Sacramento Kings|  4| 11|  0|  2|  6|  8|  0|  1|  1|  0|  4|  0|  4|  1| 14| -3|        0|           1996|        1|NULL|152.0|             177.8|  NULL|      1529|       G|0.48209366391184577|0.36363636363636365| 0.2159827213822894|   0.0|(2,[0],[1.0])|\n",
      "|     Michael Smith|      1|    Sacramento Kings|  2|  3|  0|  0|  4|  4|  2|  8| 10|  1|  2|  0|  4|  4|  8|-10|        0|           1996|        1|NULL|230.0|             203.2|  NULL|      1485|       F| 0.8403361344537815| 0.6666666666666666| 0.4098360655737705|   1.0|(2,[1],[1.0])|\n",
      "|     Michael Smith|      1|    Sacramento Kings|  2|  3|  0|  0|  4|  4|  2|  8| 10|  1|  2|  0|  4|  4|  8|-10|        0|           1996|        1|NULL|225.0|            208.28|  NULL|      1485|       F| 0.8403361344537815| 0.6666666666666666| 0.4098360655737705|   1.0|(2,[1],[1.0])|\n",
      "|    Lionel Simmons|      1|    Sacramento Kings|  2|  6|  2|  4|  0|  0|  1|  1|  2|  1|  1|  0|  4|  2|  6| -3|        0|           1996|        1|NULL|210.0|            200.66|  NULL|      1080|       F|                0.5|                0.5|0.36363636363636365|   1.0|(2,[1],[1.0])|\n",
      "|    Duane Causwell|      1|    Sacramento Kings|  1|  1|  0|  0|  1|  2|  1|  2|  3|  1|  0|  2|  1|  4|  3|  1|        0|           1996|        1|NULL|240.0|            213.36|  NULL|       986|       C|  0.797872340425532|                1.0| 0.2577319587628866|   2.0|    (2,[],[])|\n",
      "|      Kevin Willis|      1|     Houston Rockets|  3| 12|  0|  1|  2|  2|  1|  4|  5|  0|  0|  0|  2|  3|  8|  8|        1|           1996|        1|NULL|220.0|            213.36|  NULL|      2320|       F| 0.3105590062111801|               0.25|0.13440860215053763|   1.0|(2,[1],[1.0])|\n",
      "|      Matt Maloney|      1|     Houston Rockets|  3|  8|  1|  5|  1|  2|  1|  1|  2|  1|  1|  0|  1|  1|  8|  6|        1|           1996|        1|NULL|192.0|             190.5|  NULL|      1955|       G| 0.4504504504504504|             0.4375|0.09191176470588235|   0.0|(2,[0],[1.0])|\n",
      "|        Mario Elie|      1|     Houston Rockets|  7| 12|  3|  6|  3|  4|  4|  0|  4|  3|  2|  0|  0|  4| 20| 15|        1|           1996|        1|NULL|210.0|195.57999999999998|  NULL|      1941|       G| 0.7267441860465116| 0.7083333333333334|                0.0|   0.0|(2,[0],[1.0])|\n",
      "|Othella Harrington|      1|     Houston Rockets|  4|  6|  0|  0|  0|  0|  3|  3|  6|  1|  1|  0|  2|  2|  8| -5|        0|           1996|        1|NULL|235.0|            205.74|  NULL|      1059|       F| 0.6666666666666666| 0.6666666666666666| 0.2222222222222222|   1.0|(2,[1],[1.0])|\n",
      "|  Randy Livingston|      1|     Houston Rockets|  1|  2|  0|  0|  0|  3|  0|  1|  1|  1|  1|  0|  2|  4|  2|  8|        0|           1996|        1|NULL|209.0|            193.04|  NULL|       821|       G| 0.3012048192771084|                0.5| 0.3164556962025316|   0.0|(2,[0],[1.0])|\n",
      "|      Matt Bullard|      1|     Houston Rockets|  3|  5|  2|  3|  0|  0|  0|  2|  2|  2|  2|  0|  1|  0|  8|  0|        0|           1996|        1|NULL|215.0|            208.28|  NULL|       818|       F|                0.8|                0.8|              0.125|   1.0|(2,[1],[1.0])|\n",
      "|          Sam Mack|      1|     Houston Rockets|  0|  2|  0|  1|  0|  0|  1|  0|  1|  1|  0|  0|  2|  0|  0| -1|        0|           1996|        1|NULL|220.0|            200.66|  NULL|       324|       F|                0.0|                0.0|                0.4|   1.0|(2,[1],[1.0])|\n",
      "|       Tracy Moore|      1|     Houston Rockets|  0|  5|  0|  3|  0|  0|  0|  1|  1|  1|  0|  0|  0|  0|  0| -5|        0|           1996|        1|NULL|200.0|            193.04|  NULL|       184|       G|                0.0|                0.0|                0.0|   0.0|(2,[0],[1.0])|\n",
      "|     Emanual Davis|      1|     Houston Rockets|  0|  1|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0| -3|        0|           1996|        1|NULL|195.0|            193.04|  NULL|       104|       G|                0.0|                0.0|                0.0|   0.0|(2,[0],[1.0])|\n",
      "|        Loy Vaught|      2|Los Angeles Clippers|  9| 19|  0|  0|  1|  2|  3| 11| 14|  2|  0|  0|  4|  3| 19|  9|        1|           1996|        1|NULL|230.0|            205.74|  NULL|      2324|       F| 0.4778672032193159|0.47368421052631576| 0.1545595054095827|   1.0|(2,[1],[1.0])|\n",
      "|       Malik Sealy|      2|Los Angeles Clippers|  7| 15|  0|  0|  1|  2|  3|  5|  8|  1|  1|  1|  2|  1| 15|  9|        1|           1996|        1|NULL|190.0|             203.2|  NULL|      2312|       G| 0.4722921914357682| 0.4666666666666667|0.10593220338983049|   0.0|(2,[0],[1.0])|\n",
      "+------------------+-------+--------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---------+---------------+---------+----+-----+------------------+------+----------+--------+-------------------+-------------------+-------------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "onehotencoder_embarked_vector = OneHotEncoder(inputCol=\"PosNum\", outputCol=\"PosVec\")\n",
    "df_boxscore = onehotencoder_embarked_vector.fit(df_boxscore).transform(df_boxscore)\n",
    "df_boxscore.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776ffef8-d6dd-4928-8528-766628379418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column2drop = ('playerName', 'game_id', 'teamName', 'seasonStartYear', 'Ht', 'Pos', 'Position', 'Wt', 'feet', 'inches')\n",
    "df_boxscore = df_boxscore.drop(*column2drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d277e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing correlated features\n",
    "too_correlated = ('FG', 'FT', 'TRB', 'TSP')\n",
    "df_boxscore = df_boxscore.drop(*too_correlated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87e25be7-ea01-404c-bc99-c1b40576f704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FGA: integer (nullable = true)\n",
      " |-- 3P: integer (nullable = true)\n",
      " |-- 3PA: integer (nullable = true)\n",
      " |-- FTA: integer (nullable = true)\n",
      " |-- ORB: integer (nullable = true)\n",
      " |-- DRB: integer (nullable = true)\n",
      " |-- AST: integer (nullable = true)\n",
      " |-- STL: integer (nullable = true)\n",
      " |-- BLK: integer (nullable = true)\n",
      " |-- TOV: integer (nullable = true)\n",
      " |-- PF: integer (nullable = true)\n",
      " |-- PTS: integer (nullable = true)\n",
      " |-- +/-: integer (nullable = true)\n",
      " |-- isStarter: integer (nullable = true)\n",
      " |-- isRegular: integer (nullable = true)\n",
      " |-- MP_seconds: integer (nullable = true)\n",
      " |-- EFG: double (nullable = true)\n",
      " |-- TO_ratio: double (nullable = true)\n",
      " |-- PosNum: double (nullable = false)\n",
      " |-- PosVec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_boxscore.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f4fe7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values and frequencies in PosNum:\n",
      "0.0: 232742\n",
      "1.0: 224245\n",
      "2.0: 82184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Are data balanced?\n",
    "categorical_columns = ['PosNum']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    distinct_values = df_boxscore.groupBy(column).count().collect()\n",
    "    print(f\"Distinct values and frequencies in {column}:\")\n",
    "    for row in distinct_values:\n",
    "        value = row[column]\n",
    "        frequency = row[\"count\"]\n",
    "        print(f\"{value}: {frequency}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f4c94-0db5-4017-8c4c-48e59052c0c5",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a3073e2-b5d4-4904-977e-382992b9e279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39d8ac46-3802-4606-a69b-94b5b2093673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FGA', '3P', '3PA', 'FTA', 'ORB', 'DRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', '+/-', 'isStarter', 'isRegular', 'MP_seconds', 'EFG', 'TO_ratio']\n"
     ]
    }
   ],
   "source": [
    "num_col = [item[0] for item in df_boxscore.dtypes if not item[1].startswith('string')]\n",
    "num_col.remove(\"PosNum\")\n",
    "num_col.remove(\"PosVec\")\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf4934fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---------+---------+----------+-------------------+-------------------+------+-------------+--------------------+--------------------+\n",
      "|FGA| 3P|3PA|FTA|ORB|DRB|AST|STL|BLK|TOV| PF|PTS|+/-|isStarter|isRegular|MP_seconds|                EFG|           TO_ratio|PosNum|       PosVec|            features|     features_scaled|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---------+---------+----------+-------------------+-------------------+------+-------------+--------------------+--------------------+\n",
      "| 11|  0|  0|  0|  1|  3|  4|  1|  1|  4|  5| 14| -2|        1|        1|      2240| 0.6363636363636364|0.21052631578947367|   1.0|(2,[1],[1.0])|[11.0,0.0,0.0,0.0...|[0.25,0.0,0.0,0.0...|\n",
      "|  4|  0|  0|  4|  2|  5|  3|  1|  0|  4|  3|  1|-12|        1|        1|      1894|                0.0|0.31347962382445144|   2.0|    (2,[],[])|[4.0,0.0,0.0,4.0,...|[0.09090909090909...|\n",
      "| 13|  1|  2|  2|  0|  2|  5|  1|  1|  2|  2| 17| -7|        1|        1|      1767| 0.5769230769230769|0.09578544061302681|   0.0|(2,[0],[1.0])|[13.0,1.0,2.0,2.0...|[0.29545454545454...|\n",
      "| 11|  0|  0|  2|  1|  5|  0|  0|  2|  1|  2|  8| -7|        1|        1|      1513| 0.2727272727272727|0.07763975155279502|   1.0|(2,[1],[1.0])|[11.0,0.0,0.0,2.0...|[0.25,0.0,0.0,0.0...|\n",
      "| 11|  0|  2|  8|  0|  1|  0|  4|  0|  4|  1| 14| -3|        0|        1|      1529|0.36363636363636365| 0.2159827213822894|   0.0|(2,[0],[1.0])|[11.0,0.0,2.0,8.0...|[0.25,0.0,0.08333...|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---------+---------+----------+-------------------+-------------------+------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "# Selezionare tutte le colonne\n",
    "selected_columns = num_col\n",
    "\n",
    "# Creare un VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol=\"features\")\n",
    "\n",
    "# Applicare l'assemblatore\n",
    "output_dataset = assembler.transform(df_boxscore)\n",
    "\n",
    "# Creare uno scaler per normalizzare le features\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "\n",
    "# Applicare lo scaler\n",
    "output_dataset = scaler.fit(output_dataset).transform(output_dataset)\n",
    "output_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fae745a-8d01-47bd-b583-178b6186af7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|features_scaled                                                                                                                                                                                                                                                                          |PosNum|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|[0.25,0.0,0.0,0.0,0.05555555555555555,0.13043478260869565,0.16,0.1,0.07692307692307693,0.3333333333333333,0.7142857142857142,0.19999999999999998,0.48245614035087714,1.0,1.0,0.5746536685479733,0.4242424242424242,0.21052631578947367]                                                  |1.0   |\n",
      "|[0.09090909090909091,0.0,0.0,0.10256410256410256,0.1111111111111111,0.21739130434782608,0.12,0.1,0.0,0.3333333333333333,0.42857142857142855,0.014285714285714285,0.39473684210526316,1.0,1.0,0.4858902001026167,0.0,0.31347962382445144]                                                 |2.0   |\n",
      "|[0.29545454545454547,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.0,0.08695652173913043,0.2,0.1,0.07692307692307693,0.16666666666666666,0.2857142857142857,0.24285714285714285,0.43859649122807015,1.0,1.0,0.45330938943047716,0.3846153846153846,0.09578544061302681]  |0.0   |\n",
      "|[0.25,0.0,0.0,0.05128205128205128,0.05555555555555555,0.21739130434782608,0.0,0.0,0.15384615384615385,0.08333333333333333,0.2857142857142857,0.11428571428571428,0.43859649122807015,1.0,1.0,0.38814776808619805,0.1818181818181818,0.07763975155279502]                                 |1.0   |\n",
      "|[0.25,0.0,0.08333333333333333,0.20512820512820512,0.0,0.043478260869565216,0.0,0.4,0.0,0.3333333333333333,0.14285714285714285,0.19999999999999998,0.47368421052631576,0.0,1.0,0.392252437147255,0.24242424242424243,0.2159827213822894]                                                  |0.0   |\n",
      "|[0.06818181818181818,0.0,0.0,0.10256410256410256,0.1111111111111111,0.34782608695652173,0.04,0.2,0.0,0.3333333333333333,0.5714285714285714,0.11428571428571428,0.4122807017543859,0.0,1.0,0.3809645972293484,0.4444444444444444,0.4098360655737705]                                      |1.0   |\n",
      "|[0.06818181818181818,0.0,0.0,0.10256410256410256,0.1111111111111111,0.34782608695652173,0.04,0.2,0.0,0.3333333333333333,0.5714285714285714,0.11428571428571428,0.4122807017543859,0.0,1.0,0.3809645972293484,0.4444444444444444,0.4098360655737705]                                      |1.0   |\n",
      "|[0.13636363636363635,0.14285714285714285,0.16666666666666666,0.0,0.05555555555555555,0.043478260869565216,0.04,0.1,0.0,0.3333333333333333,0.2857142857142857,0.08571428571428572,0.47368421052631576,0.0,1.0,0.27706516162134426,0.3333333333333333,0.36363636363636365]                 |1.0   |\n",
      "|[0.022727272727272728,0.0,0.0,0.05128205128205128,0.05555555555555555,0.08695652173913043,0.04,0.0,0.15384615384615385,0.08333333333333333,0.5714285714285714,0.04285714285714286,0.5087719298245614,0.0,1.0,0.2529502308876347,0.6666666666666666,0.2577319587628866]                   |2.0   |\n",
      "|[0.2727272727272727,0.0,0.041666666666666664,0.05128205128205128,0.05555555555555555,0.17391304347826086,0.0,0.0,0.0,0.16666666666666666,0.42857142857142855,0.11428571428571428,0.5701754385964912,1.0,1.0,0.595177013853258,0.16666666666666666,0.13440860215053763]                   |1.0   |\n",
      "|[0.18181818181818182,0.07142857142857142,0.20833333333333331,0.05128205128205128,0.05555555555555555,0.043478260869565216,0.04,0.1,0.0,0.08333333333333333,0.14285714285714285,0.11428571428571428,0.5526315789473684,1.0,1.0,0.5015392508978963,0.29166666666666663,0.09191176470588235]|0.0   |\n",
      "|[0.2727272727272727,0.21428571428571427,0.25,0.10256410256410256,0.2222222222222222,0.0,0.12,0.2,0.0,0.0,0.5714285714285714,0.2857142857142857,0.631578947368421,1.0,1.0,0.4979476654694715,0.4722222222222222,0.0]                                                                      |0.0   |\n",
      "|[0.13636363636363635,0.0,0.0,0.0,0.16666666666666666,0.13043478260869565,0.04,0.1,0.0,0.16666666666666666,0.2857142857142857,0.11428571428571428,0.45614035087719296,0.0,1.0,0.271677783478707,0.4444444444444444,0.2222222222222222]                                                    |1.0   |\n",
      "|[0.045454545454545456,0.0,0.0,0.07692307692307693,0.0,0.043478260869565216,0.04,0.1,0.0,0.16666666666666666,0.5714285714285714,0.02857142857142857,0.5701754385964912,0.0,1.0,0.21062083119548486,0.3333333333333333,0.3164556962025316]                                                 |0.0   |\n",
      "|[0.11363636363636365,0.14285714285714285,0.125,0.0,0.0,0.08695652173913043,0.08,0.2,0.0,0.08333333333333333,0.0,0.11428571428571428,0.5,0.0,1.0,0.20985120574653668,0.5333333333333333,0.125]                                                                                            |1.0   |\n",
      "|(18,[0,2,4,6,9,12,14,15,17],[0.045454545454545456,0.041666666666666664,0.05555555555555555,0.04,0.16666666666666666,0.49122807017543857,1.0,0.08311954848640328,0.4])                                                                                                                    |1.0   |\n",
      "|(18,[0,2,5,6,12,14,15],[0.11363636363636365,0.125,0.043478260869565216,0.04,0.45614035087719296,1.0,0.04720369420215495])                                                                                                                                                                |0.0   |\n",
      "|(18,[0,2,10,12,14,15],[0.022727272727272728,0.041666666666666664,0.14285714285714285,0.47368421052631576,1.0,0.02668034889687019])                                                                                                                                                       |0.0   |\n",
      "|[0.4318181818181818,0.0,0.0,0.05128205128205128,0.16666666666666666,0.4782608695652174,0.08,0.0,0.0,0.3333333333333333,0.42857142857142855,0.2714285714285714,0.5789473684210527,1.0,1.0,0.5962031811185223,0.3157894736842105,0.1545595054095827]                                       |1.0   |\n",
      "|[0.34090909090909094,0.0,0.0,0.05128205128205128,0.16666666666666666,0.21739130434782608,0.04,0.1,0.07692307692307693,0.16666666666666666,0.14285714285714285,0.21428571428571427,0.5789473684210527,1.0,1.0,0.5931246793227296,0.3111111111111111,0.10593220338983049]                  |0.0   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificationData = output_dataset.select(\"features_scaled\", \"PosNum\")\n",
    "\n",
    "classificationData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed8557f2-62b9-4b58-8b98-fbb65c38ca05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = classificationData.randomSplit([0.7, 0.3],seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fff4b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation split\n",
    "(trainingData, valData) = trainingData.randomSplit([0.8, 0.2],seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39eab193-3f3b-453e-b018-b15afbe694db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|features_scaled                                                                                                                                                                                                                          |PosNum|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|(18,[0,1,2,3,4,5,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.05555555555555555,0.043478260869565216,0.09999999999999999,0.5614035087719298,0.02539763981528989,0.7777777777777778]) |0.0   |\n",
      "|(18,[0,1,2,3,4,5,11,12,15,16],[0.11363636363636365,0.14285714285714285,0.125,0.05128205128205128,0.05555555555555555,0.043478260869565216,0.11428571428571428,0.6052631578947368,0.19881990764494611,0.39999999999999997])               |0.0   |\n",
      "|(18,[0,1,2,3,4,5,11,12,15,16],[0.11363636363636365,0.14285714285714285,0.125,0.23076923076923075,0.05555555555555555,0.043478260869565216,0.21428571428571427,0.5175438596491228,0.24628014366341713,0.39999999999999997])               |0.0   |\n",
      "|(18,[0,1,2,3,4,5,11,12,15,16],[0.11363636363636365,0.14285714285714285,0.125,0.23076923076923075,0.05555555555555555,0.043478260869565216,0.21428571428571427,0.5175438596491228,0.24628014366341713,0.39999999999999997])               |1.0   |\n",
      "|(18,[0,1,2,3,4,7,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.16666666666666666,0.05128205128205128,0.05555555555555555,0.1,0.07142857142857142,0.5789473684210527,0.24114930733709594,0.19999999999999998])                  |1.0   |\n",
      "|(18,[0,1,2,3,4,7,11,12,15,16],[0.1590909090909091,0.07142857142857142,0.16666666666666666,0.07692307692307693,0.05555555555555555,0.1,0.08571428571428572,0.4649122807017544,0.3712160082093381,0.14285714285714285])                    |1.0   |\n",
      "|(18,[0,1,2,3,4,8,11,12,15,16],[0.18181818181818182,0.14285714285714285,0.20833333333333331,0.05128205128205128,0.05555555555555555,0.07692307692307693,0.17142857142857143,0.5438596491228069,0.538994356080041,0.41666666666666663])    |0.0   |\n",
      "|(18,[0,1,2,3,4,8,11,12,15,16],[0.18181818181818182,0.21428571428571427,0.16666666666666666,0.05128205128205128,0.05555555555555555,0.07692307692307693,0.14285714285714285,0.5614035087719298,0.4061056952283222,0.375])                 |1.0   |\n",
      "|(18,[0,1,2,3,4,10,11,12,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.05555555555555555,0.14285714285714285,0.05714285714285714,0.5614035087719298,0.058748075936377625,1.0])              |0.0   |\n",
      "|(18,[0,1,2,3,4,10,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.05555555555555555,0.14285714285714285,0.05714285714285714,0.4122807017543859,0.19933299127757823,0.3333333333333333]) |1.0   |\n",
      "|(18,[0,1,2,3,4,10,11,12,15,16],[0.18181818181818182,0.14285714285714285,0.125,0.05128205128205128,0.05555555555555555,0.2857142857142857,0.15714285714285714,0.5438596491228069,0.22601334017444843,0.41666666666666663])                |1.0   |\n",
      "|(18,[0,1,2,3,4,10,11,12,15,16],[0.25,0.21428571428571427,0.25,0.05128205128205128,0.05555555555555555,0.2857142857142857,0.19999999999999998,0.4122807017543859,0.35146228835300153,0.3939393939393939])                                 |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.05555555555555555,0.07142857142857142,0.5526315789473684,1.0,0.044125192406362236,0.8333333333333333])               |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.05555555555555555,0.05714285714285714,0.4298245614035088,1.0,0.17136993329912775,0.5])                                |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.05555555555555555,0.07142857142857142,0.45614035087719296,1.0,0.1690610569522832,0.5])                                |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.045454545454545456,0.14285714285714285,0.08333333333333333,0.05128205128205128,0.1111111111111111,0.09999999999999999,0.49122807017543857,1.0,0.08619805028219599,1.0])                                |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.06818181818181818,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.05555555555555555,0.07142857142857142,0.45614035087719296,1.0,0.06798358132375577,0.5555555555555556])                |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.06818181818181818,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.1111111111111111,0.09999999999999999,0.5526315789473684,1.0,0.10826064648537712,0.5555555555555556])                  |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.06818181818181818,0.07142857142857142,0.041666666666666664,0.07692307692307693,0.05555555555555555,0.09999999999999999,0.3684210526315789,1.0,0.1513596716264751,0.5555555555555556])                  |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.06818181818181818,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.05555555555555555,0.05714285714285714,0.48245614035087714,1.0,0.02077988712160082,0.3333333333333333])                 |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.06818181818181818,0.14285714285714285,0.08333333333333333,0.05128205128205128,0.05555555555555555,0.12857142857142856,0.5438596491228069,1.0,0.10800410466906105,0.8888888888888888])                  |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.09090909090909091,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.05555555555555555,0.08571428571428572,0.5263157894736842,1.0,0.1090302719343253,0.41666666666666663])                 |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.09090909090909091,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.05555555555555555,0.08571428571428572,0.5263157894736842,1.0,0.16957414058491532,0.41666666666666663])                |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.09090909090909091,0.07142857142857142,0.125,0.05128205128205128,0.1111111111111111,0.09999999999999999,0.4649122807017544,1.0,0.23524884556182657,0.41666666666666663])                                |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.13636363636363635,0.07142857142857142,0.08333333333333333,0.02564102564102564,0.05555555555555555,0.05714285714285714,0.42105263157894735,1.0,0.13904566444330424,0.16666666666666666])                |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.13636363636363635,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.05555555555555555,0.08571428571428572,0.587719298245614,1.0,0.14725500256541815,0.2777777777777778])                   |1.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.1590909090909091,0.21428571428571427,0.16666666666666666,0.05128205128205128,0.05555555555555555,0.18571428571428572,0.5350877192982456,1.0,0.29040533606977936,0.5238095238095237])                   |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.18181818181818182,0.14285714285714285,0.125,0.05128205128205128,0.05555555555555555,0.15714285714285714,0.5526315789473684,1.0,0.19035402770651616,0.41666666666666663])                               |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.20454545454545456,0.14285714285714285,0.16666666666666666,0.3333333333333333,0.1111111111111111,0.32857142857142857,0.5350877192982456,1.0,0.3919958953309389,0.37037037037037035])                    |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,14,15,16],[0.2272727272727273,0.07142857142857142,0.125,0.02564102564102564,0.05555555555555555,0.11428571428571428,0.5175438596491228,1.0,0.30118009235505383,0.2333333333333333])                                 |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,15,16],[0.045454545454545456,0.07142857142857142,0.08333333333333333,0.10256410256410256,0.05555555555555555,0.09999999999999999,0.49122807017543857,0.1064648537711647,0.5])                                       |0.0   |\n",
      "|(18,[0,1,2,3,4,11,12,15,16],[0.1590909090909091,0.14285714285714285,0.16666666666666666,0.02564102564102564,0.05555555555555555,0.12857142857142856,0.5175438596491228,0.29604925602873267,0.38095238095238093])                         |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.13043478260869565,0.04,0.09999999999999999,0.43859649122807015,0.28168291431503334,0.5555555555555556])                 |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.09090909090909091,0.07142857142857142,0.041666666666666664,0.10256410256410256,0.043478260869565216,0.04,0.09999999999999999,0.5087719298245614,0.21395587480759362,0.41666666666666663])               |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.09090909090909091,0.07142857142857142,0.16666666666666666,0.02564102564102564,0.043478260869565216,0.08,0.05714285714285714,0.4298245614035088,0.17239610056439197,0.25])                               |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.041666666666666664,0.15384615384615385,0.08695652173913043,0.04,0.17142857142857143,0.43859649122807015,0.31452026680348893,0.4666666666666666])                |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.13636363636363635,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.08695652173913043,0.04,0.09999999999999999,0.4649122807017544,0.37737301180092353,0.2777777777777778])                 |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.13636363636363635,0.07142857142857142,0.125,0.05128205128205128,0.043478260869565216,0.04,0.12857142857142856,0.49122807017543857,0.16572601334017445,0.3888888888888889])                              |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.13636363636363635,0.07142857142857142,0.125,0.05128205128205128,0.043478260869565216,0.08,0.08571428571428572,0.49122807017543857,0.19856336582863005,0.2777777777777778])                              |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.13636363636363635,0.07142857142857142,0.125,0.15384615384615385,0.21739130434782608,0.12,0.09999999999999999,0.3508771929824561,0.37942534633145203,0.16666666666666666])                               |1.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.13636363636363635,0.07142857142857142,0.20833333333333331,0.10256410256410256,0.08695652173913043,0.2,0.12857142857142856,0.631578947368421,0.2483324781939456,0.2777777777777778])                     |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.1590909090909091,0.07142857142857142,0.20833333333333331,0.1282051282051282,0.043478260869565216,0.04,0.12857142857142856,0.3070175438596491,0.3547973319651103,0.23809523809523808])                   |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.18181818181818182,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.043478260869565216,0.04,0.19999999999999998,0.5789473684210527,0.34787070292457667,0.5416666666666666])                |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.20454545454545456,0.14285714285714285,0.16666666666666666,0.05128205128205128,0.17391304347826086,0.04,0.15714285714285714,0.6754385964912281,0.3781426372498717,0.37037037037037035])                  |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.2272727272727273,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.043478260869565216,0.04,0.14285714285714285,0.5175438596491228,0.4099538224730631,0.3])                                  |0.0   |\n",
      "|(18,[0,1,2,3,5,6,11,12,15,16],[0.25,0.21428571428571427,0.29166666666666663,0.10256410256410256,0.08695652173913043,0.08,0.21428571428571427,0.5438596491228069,0.40200102616726524,0.3333333333333333])                                 |0.0   |\n",
      "|(18,[0,1,2,3,5,7,11,12,15,16],[0.09090909090909091,0.07142857142857142,0.08333333333333333,0.10256410256410256,0.08695652173913043,0.30000000000000004,0.09999999999999999,0.48245614035087714,0.1906105695228322,0.25])                 |1.0   |\n",
      "|(18,[0,1,2,3,5,7,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.125,0.1282051282051282,0.08695652173913043,0.1,0.17142857142857143,0.6578947368421052,0.18394048229861468,0.4666666666666666])                                  |1.0   |\n",
      "|(18,[0,1,2,3,5,8,11,12,15,16],[0.25,0.14285714285714285,0.25,0.10256410256410256,0.13043478260869565,0.23076923076923078,0.21428571428571427,0.5350877192982456,0.41893278604412515,0.3636363636363636])                                 |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.043478260869565216,0.42857142857142855,0.05714285714285714,0.4298245614035088,0.370959466393022,0.5])                |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.10256410256410256,0.08695652173913043,0.5714285714285714,0.09999999999999999,0.43859649122807015,0.2203694202154951,0.5])                |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.10256410256410256,0.13043478260869565,0.2857142857142857,0.08571428571428572,0.47368421052631576,0.2675731144176501,0.5])                |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.08695652173913043,0.5714285714285714,0.08571428571428572,0.587719298245614,0.27526936890713183,0.5555555555555556])   |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.14285714285714285,0.07142857142857142,0.5438596491228069,0.0836326321190354,0.3333333333333333]) |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.08333333333333333,0.02564102564102564,0.043478260869565216,0.14285714285714285,0.07142857142857142,0.5614035087719298,0.06439199589533094,0.5555555555555556]) |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.08333333333333333,0.02564102564102564,0.13043478260869565,0.7142857142857142,0.08571428571428572,0.4298245614035088,0.34684453565931245,0.5555555555555556])   |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.125,0.05128205128205128,0.13043478260869565,0.14285714285714285,0.07142857142857142,0.6754385964912281,0.27706516162134426,0.3333333333333333])                |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.06818181818181818,0.07142857142857142,0.125,0.07692307692307693,0.043478260869565216,0.14285714285714285,0.08571428571428572,0.5087719298245614,0.16675218060543867,0.3333333333333333])               |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.09090909090909091,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.42857142857142855,0.12857142857142856,0.5263157894736842,0.21190354027706515,0.5833333333333333])|1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.09090909090909091,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.043478260869565216,0.14285714285714285,0.07142857142857142,0.4473684210526315,0.12185736275012826,0.25])               |2.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.09090909090909091,0.14285714285714285,0.125,0.05128205128205128,0.043478260869565216,0.2857142857142857,0.11428571428571428,0.4473684210526315,0.18471010774756283,0.5])                               |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.09090909090909091,0.14285714285714285,0.125,0.05128205128205128,0.08695652173913043,0.14285714285714285,0.11428571428571428,0.49122807017543857,0.12314007183170857,0.5])                              |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.09090909090909091,0.21428571428571427,0.125,0.02564102564102564,0.17391304347826086,0.2857142857142857,0.12857142857142856,0.5438596491228069,0.25885069266290406,0.75])                               |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.2608695652173913,0.42857142857142855,0.15714285714285714,0.5701754385964912,0.24037968188814776,0.6])                 |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.043478260869565216,0.14285714285714285,0.07142857142857142,0.47368421052631576,0.1888147768086198,0.19999999999999998])|1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.043478260869565216,0.42857142857142855,0.12857142857142856,0.5614035087719298,0.38481272447408926,0.4666666666666666]) |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.08333333333333333,0.07692307692307693,0.043478260869565216,0.14285714285714285,0.11428571428571428,0.5964912280701754,0.28142637249871727,0.3333333333333333]) |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.07142857142857142,0.16666666666666666,0.05128205128205128,0.043478260869565216,0.14285714285714285,0.05714285714285714,0.5,0.3168291431503335,0.19999999999999998])                |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.14285714285714285,0.08333333333333333,0.05128205128205128,0.13043478260869565,0.42857142857142855,0.11428571428571428,0.45614035087719296,0.19548486403283735,0.39999999999999997])|0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.14285714285714285,0.125,0.05128205128205128,0.08695652173913043,0.2857142857142857,0.14285714285714285,0.5526315789473684,0.20061570035915854,0.5333333333333333])                 |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.14285714285714285,0.20833333333333331,0.05128205128205128,0.043478260869565216,0.14285714285714285,0.11428571428571428,0.6403508771929824,0.19035402770651616,0.39999999999999997])|0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.11363636363636365,0.14285714285714285,0.20833333333333331,0.05128205128205128,0.08695652173913043,0.14285714285714285,0.11428571428571428,0.5175438596491228,0.21754746023601845,0.39999999999999997]) |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.13636363636363635,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.043478260869565216,0.42857142857142855,0.09999999999999999,0.5964912280701754,0.21190354027706515,0.2777777777777778]) |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.13636363636363635,0.14285714285714285,0.20833333333333331,0.05128205128205128,0.13043478260869565,0.5714285714285714,0.11428571428571428,0.5350877192982456,0.3022062596203181,0.3333333333333333])    |2.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.1590909090909091,0.07142857142857142,0.08333333333333333,0.05128205128205128,0.043478260869565216,0.14285714285714285,0.08571428571428572,0.5175438596491228,0.3204207285787583,0.23809523809523808])  |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.1590909090909091,0.07142857142857142,0.125,0.02564102564102564,0.043478260869565216,0.2857142857142857,0.09999999999999999,0.32456140350877194,0.24243201641867623,0.3333333333333333])                |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.1590909090909091,0.07142857142857142,0.16666666666666666,0.05128205128205128,0.08695652173913043,0.14285714285714285,0.09999999999999999,0.5087719298245614,0.2560287326834274,0.3333333333333333])    |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.18181818181818182,0.07142857142857142,0.125,0.05128205128205128,0.043478260869565216,0.42857142857142855,0.14285714285714285,0.5789473684210527,0.2652642380708055,0.375])                             |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.18181818181818182,0.21428571428571427,0.20833333333333331,0.05128205128205128,0.08695652173913043,0.42857142857142855,0.18571428571428572,0.47368421052631576,0.45715751667521803,0.4583333333333333]) |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.20454545454545456,0.07142857142857142,0.125,0.10256410256410256,0.13043478260869565,0.2857142857142857,0.18571428571428572,0.35964912280701755,0.3260646485377116,0.3333333333333333])                 |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.2272727272727273,0.07142857142857142,0.08333333333333333,0.1794871794871795,0.043478260869565216,0.14285714285714285,0.21428571428571427,0.5,0.362237044638276,0.3])                                   |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.2272727272727273,0.2857142857142857,0.3333333333333333,0.10256410256410256,0.08695652173913043,0.7142857142857142,0.2571428571428571,0.631578947368421,0.3919958953309389,0.4666666666666666])         |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.25,0.14285714285714285,0.16666666666666666,0.07692307692307693,0.17391304347826086,0.14285714285714285,0.17142857142857143,0.45614035087719296,0.306054386865059,0.303030303030303])                   |0.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.25,0.21428571428571427,0.29166666666666663,0.05128205128205128,0.13043478260869565,0.2857142857142857,0.21428571428571427,0.5701754385964912,0.3586454592098512,0.3939393939393939])                   |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.2727272727272727,0.21428571428571427,0.3333333333333333,0.23076923076923075,0.30434782608695654,0.14285714285714285,0.2857142857142857,0.631578947368421,0.45330938943047716,0.36111111111111105])     |1.0   |\n",
      "|(18,[0,1,2,3,5,10,11,12,15,16],[0.3181818181818182,0.21428571428571427,0.41666666666666663,0.05128205128205128,0.13043478260869565,0.42857142857142855,0.21428571428571427,0.3771929824561403,0.43432529502308875,0.30952380952380953])  |1.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.05714285714285714,0.5526315789473684,1.0,0.034889687018984095,1.0])                             |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.07142857142857142,0.3771929824561403,1.0,0.14648537711646997,1.0])                              |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.07142857142857142,0.4649122807017544,1.0,0.15059004617752692,1.0])                              |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.07142857142857142,0.5438596491228069,1.0,0.0336069779374038,1.0])                               |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.13043478260869565,0.05714285714285714,0.48245614035087714,1.0,0.14109799897383274,1.0])                              |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.07692307692307693,0.043478260869565216,0.07142857142857142,0.5,1.0,0.07337095946639302,1.0])                                             |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.10256410256410256,0.043478260869565216,0.09999999999999999,0.5438596491228069,1.0,0.03642893791688045,1.0])                              |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.022727272727272728,0.07142857142857142,0.041666666666666664,0.10256410256410256,0.08695652173913043,0.09999999999999999,0.5087719298245614,1.0,0.06618778860954336,1.0])                               |1.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.02564102564102564,0.043478260869565216,0.08571428571428572,0.5438596491228069,1.0,0.06054386865059004,0.8333333333333333])               |1.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.04285714285714286,0.5087719298245614,1.0,0.064648537711647,0.5])                                |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.07142857142857142,0.45614035087719296,1.0,0.0931246793227296,0.5])                              |1.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.07142857142857142,0.5175438596491228,1.0,0.2819394561313494,0.5])                               |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.05128205128205128,0.043478260869565216,0.08571428571428572,0.5350877192982456,1.0,0.06362237044638276,0.8333333333333333])               |0.0   |\n",
      "|(18,[0,1,2,3,5,11,12,14,15,16],[0.045454545454545456,0.07142857142857142,0.041666666666666664,0.15384615384615385,0.13043478260869565,0.11428571428571428,0.5175438596491228,1.0,0.19343252950230885,0.5])                               |0.0   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trainingData.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac8bb7-28fc-46e1-8199-6ea7d1f76e68",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01e8c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(importance):\n",
    "    keys = importance.keys()\n",
    "    values = importance.values()\n",
    "\n",
    "    # Plot the dictionary\n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.bar(keys, values)\n",
    "    plt.xlabel(\"Keys\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.title(\"Dictionary Plot\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b6989db-41fe-499b-b2ac-1d4dfdcaa4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'maxDepth': 7, 'maxBins': 32, 'impurity': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6367104705383637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'maxDepth': 3, 'maxBins': 32, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.5965583933870284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'maxDepth': 9, 'maxBins': 32, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6430293556591776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'maxDepth': 5, 'maxBins': 64, 'impurity': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6237680161085205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'maxDepth': 9, 'maxBins': 64, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6429498728274693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'maxDepth': 5, 'maxBins': 32, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 128:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6244966087325138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "# random search\n",
    "hyperparameters = {\n",
    "    'maxDepth': [3, 5, 7, 9],\n",
    "    'maxBins' : [16, 32, 64],\n",
    "    'impurity' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "number_of_combinations = 6\n",
    "random_combinations = random.sample(list(itertools.product(*hyperparameters.values())), number_of_combinations)\n",
    "\n",
    "for combo in random_combinations:\n",
    "    param_dict = dict(zip(hyperparameters.keys(), combo))\n",
    "\n",
    "    dt = DecisionTreeClassifier(labelCol=\"PosNum\", featuresCol=\"features_scaled\", impurity=param_dict['impurity'], maxDepth=param_dict['maxDepth'], maxBins=param_dict['maxBins'])\n",
    "\n",
    "    dt = dt.fit(trainingData)\n",
    "\n",
    "    importance = {}\n",
    "    featureImportances = list(dt.featureImportances)\n",
    "\n",
    "    for i,e in enumerate(featureImportances):\n",
    "        importance[num_col[i]] = e\n",
    "    \n",
    "    plot_importance(importance)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = dt.transform(valData)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"PosNum\"\n",
    "                                                , predictionCol=\"prediction\"\n",
    "                                                , metricName=\"accuracy\")\n",
    "\n",
    "    print('With parameters', param_dict)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print('Validation accuracy =', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc3a9a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"PosNum\", featuresCol=\"features_scaled\", impurity='entropy', maxDepth=9, maxBins=64)\n",
    "\n",
    "dt = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e5a61fc-bc7f-443f-89fe-73444d27106c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(18, {0: 0.0033, 1: 0.0001, 2: 0.419, 3: 0.0003, 4: 0.1502, 5: 0.1363, 6: 0.1837, 7: 0.0005, 8: 0.0919, 9: 0.0002, 10: 0.0046, 11: 0.0003, 12: 0.0002, 13: 0.0042, 15: 0.0045, 16: 0.0007, 17: 0.0002})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8445f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FGA': 0.003335124939120823,\n",
       " '3P': 6.29903817498968e-05,\n",
       " '3PA': 0.41896335953839514,\n",
       " 'FTA': 0.00029011097003425767,\n",
       " 'ORB': 0.15018670039940937,\n",
       " 'DRB': 0.13627375017886725,\n",
       " 'AST': 0.18369958184225754,\n",
       " 'STL': 0.0005175905514565712,\n",
       " 'BLK': 0.09187494380009671,\n",
       " 'TOV': 0.0002232749044343181,\n",
       " 'PF': 0.004612412356096733,\n",
       " 'PTS': 0.00027532132552660364,\n",
       " '+/-': 0.00016610811790196544,\n",
       " 'isStarter': 0.004229797424243183,\n",
       " 'isRegular': 0.0,\n",
       " 'MP_seconds': 0.004459411441688573,\n",
       " 'EFG': 0.0006699860796762584,\n",
       " 'TO_ratio': 0.0001595357490448041}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = {}\n",
    "featureImportances = list(dt.featureImportances)\n",
    "\n",
    "for i,e in enumerate(featureImportances):\n",
    "    importance[num_col[i]] = e\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff50b822-0b33-4d44-b7d9-2896a11a4614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 152:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|     features_scaled|PosNum|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|(18,[0,1,2,3,4,7,...|   0.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   1.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   1.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[7882.0,4714.0,31...|[0.61067637715968...|       0.0|\n",
      "|(18,[0,1,2,3,5,6,...|   0.0|[12655.0,3711.0,1...|[0.76585572500605...|       0.0|\n",
      "|(18,[0,1,2,3,5,6,...|   1.0|[7741.0,3650.0,14...|[0.67085536008319...|       0.0|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = dt.transform(valData)\n",
    "\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "726a52d7-66e5-4cc6-baed-8ee0725e0bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.642870389995761\n",
      "Validation Error = 0.35713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 155:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.6414418420792568\n",
      "Test Error = 0.358558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"PosNum\"\n",
    "                                              , predictionCol=\"prediction\"\n",
    "                                              , metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Validation accuracy =', accuracy)\n",
    "print(\"Validation Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "predictions_test = dt.transform(testData)\n",
    "accuracy_test = evaluator.evaluate(predictions_test)\n",
    "print('Test accuracy =', accuracy_test)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'Ht', the decision tree obtains nearly 89% of accuracy. Without it, we reach 65% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb4b374d-8d12-406a-bc02-91b6ab5c7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for future use\n",
    "#model.save(\"path_to_save_model\")\n",
    "\n",
    "# Load the saved model\n",
    "#loaded_model = GBTClassifier.load(\"path_to_saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b37290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:03:30 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/12/11 12:03:30 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 271:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6547265790589233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "layers = [18, 40, 20, 3]  # Define the layers of the neural network\n",
    "mlp = MultilayerPerceptronClassifier(labelCol=\"PosNum\", featuresCol=\"features_scaled\", layers=layers, seed=1234)\n",
    "\n",
    "model = mlp.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(valData)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"PosNum\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Validation accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93cb64d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 273:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|     features_scaled|PosNum|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "|(18,[0,1,2,3,4,7,...|   0.0|[0.62532311456895...|[0.54701273892892...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   1.0|[0.23190297524152...|[0.43561724904586...|       1.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[0.00884651962103...|[0.37949287576483...|       1.0|\n",
      "|(18,[0,1,2,3,4,11...|   1.0|[-0.2787187647146...|[0.30504847607504...|       1.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[0.09240277351151...|[0.40182649449818...|       1.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[1.16822185414670...|[0.67104522815508...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[1.43868196034134...|[0.71201740049923...|       0.0|\n",
      "|(18,[0,1,2,3,4,11...|   0.0|[0.90514895820658...|[0.61167883673426...|       0.0|\n",
      "|(18,[0,1,2,3,5,6,...|   0.0|[2.14930682701004...|[0.85731363663766...|       0.0|\n",
      "|(18,[0,1,2,3,5,6,...|   1.0|[2.10271259807671...|[0.82394380945312...|       0.0|\n",
      "|(18,[0,1,2,3,5,6,...|   0.0|[2.58134502688066...|[0.88760047074743...|       0.0|\n",
      "|(18,[0,1,2,3,5,6,...|   0.0|[1.98320624796961...|[0.78592507874168...|       0.0|\n",
      "|(18,[0,1,2,3,5,7,...|   2.0|[1.53941328733396...|[0.73658522453388...|       0.0|\n",
      "|(18,[0,1,2,3,5,10...|   0.0|[1.00465677495417...|[0.63503346561073...|       0.0|\n",
      "|(18,[0,1,2,3,5,10...|   0.0|[0.14066156666079...|[0.35952671026859...|       1.0|\n",
      "|(18,[0,1,2,3,5,10...|   0.0|[0.86015441096809...|[0.54847203818919...|       0.0|\n",
      "|(18,[0,1,2,3,5,10...|   0.0|[1.17526518626340...|[0.64743460129508...|       0.0|\n",
      "|(18,[0,1,2,3,5,10...|   1.0|[1.40095079031870...|[0.67404447982683...|       0.0|\n",
      "|(18,[0,1,2,3,5,10...|   0.0|[2.08993596724576...|[0.77651606409247...|       0.0|\n",
      "|(18,[0,1,2,3,5,10...|   1.0|[0.01433104168986...|[0.28734730828861...|       1.0|\n",
      "+--------------------+------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8da045c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultilayerPerceptronClassificationModel: uid=MultilayerPerceptronClassifier_0ef9bb5db99d, numLayers=4, numClasses=3, numFeatures=18"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d4419",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5013b93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 25, 'maxDepth': 6, 'maxBins': 64, 'impurity': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.633584145824502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:24:47 WARN DAGScheduler: Broadcasting large task binary with size 1104.9 KiB\n",
      "23/12/11 12:24:54 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 25, 'maxDepth': 9, 'maxBins': 32, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:25:03 WARN DAGScheduler: Broadcasting large task binary with size 1423.0 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6510306273844849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:26:25 WARN DAGScheduler: Broadcasting large task binary with size 1087.8 KiB\n",
      "23/12/11 12:26:40 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/11 12:26:54 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/12/11 12:27:08 WARN DAGScheduler: Broadcasting large task binary with size 1184.6 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 50, 'maxDepth': 9, 'maxBins': 32, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:27:10 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.651494277236117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 25, 'maxDepth': 6, 'maxBins': 16, 'impurity': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.63359739296312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 25, 'maxDepth': 6, 'maxBins': 16, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6366972233997457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:30:38 WARN DAGScheduler: Broadcasting large task binary with size 1086.4 KiB\n",
      "23/12/11 12:30:52 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/11 12:31:06 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/12/11 12:31:23 WARN DAGScheduler: Broadcasting large task binary with size 1188.1 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 50, 'maxDepth': 9, 'maxBins': 16, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:31:25 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6516664900381518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:32:32 WARN DAGScheduler: Broadcasting large task binary with size 1089.2 KiB\n",
      "23/12/11 12:32:42 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/11 12:32:53 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/12/11 12:33:07 WARN DAGScheduler: Broadcasting large task binary with size 1192.6 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+4AAAFOCAYAAAAYZ0d5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArRElEQVR4nO3debglVXnv8e/PRtTLIEFaAw1to6KEq0CwhaA4oBFB9LZEvYBGAw6EXHFIrl7JcKNJbhQjaoygHVTECXEKppVGIERFAwiITTMEtJlC2yIgDqDI+N4/qk53cfoMu4fdu0739/M85zm7VtWq/a49v7XWqkpVIUmSJEmS+ukhow5AkiRJkiRNzsRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckqeeSLEzyf9ey7p1JHre+Y9pQksxLUkk2G3UskiSNiom7JEkjlOSGJHcluSPJz5Ocn+ToJCu/o6vq6Kr6uwH29c0kr+uWVdWWVXXdMGJfX5I8J8kD7UGGO5Jck+TItdjPO5N8ZhgxSpI0SibukiSN3ouraivgscBxwNuBj482pLW3lr3jK6pqS2BrmvZ/NMlu6zcySZJmJhN3SZJ6oqp+UVWLgEOBP0ryZIAkpyT5f2PbJVmQZEmSXya5NsmBSf4eeCZwQttzfUK7bSV5Qnv7kUk+leTWJDcm+auxnv0kRyT5TpLjk/wsyfVJDurc55FJ/rPtEb8uyR931j0nyfIkb09yM/CJJFckeXFnm4cmuS3JntM8BlVVXwF+BqyWuCfZIcmiJLcnWZbk9W35gcBfAIe27b9sjR58SZJ6zPlikiT1TFVdlGQ5TSJ+RXddkr2BTwEvA84Ftge2qqqvJ3kG8Jmq+tgku/4Q8EjgccCjgLOBH7Oqd38f4JPAdsBRwMeTzKmqAm4BXgRcBzwLODPJxVV1aVv3t4FtaUYNPAR4I/CHwFfb9S8EflxVS6Zqe3sgYQGwDXD5BJt8DrgS2AHYFTgnyXVt+98FPKGq/nCq+5Akaaaxx12SpH5aQZMIj/da4OSqOqeqHqiqH1XV1dPtLMksmp78P6+qO6rqBuB9wKs6m91YVR+tqvtpEvjtgccAVNUZVXVt2yP+LZqk/5mdug8A76iqu6vqLuAzwAuTbN2ufxXw6SlC3CHJz4HbgHcAr6qqa8a1YSdgP+DtVfWb9iDAx8a1QZKkjY6JuyRJ/TQHuH2C8p2Aa9dif9sBmwM3dspubO9nzM1jN6rq1+3NLQGSHJTkwnaI+s9petC369S9tap+06m/AvgP4KVJtgEOAj47RXwrqmqbqtq2qvasqtMm2GYH4PaqumOKNkiStNExcZckqWeSPI0mGf3OBKtvAh4/SdWaYre3AffSDGUfMxf40QDxPAz4MnA88Jiq2gZYDGSa+/4kzXD5lwMXVNW09zWNFcC2SbbqlHXbMFX7JUmasUzcJUnqiSRbJ3kRcBrNXPWJ5nh/HDgyyfOSPCTJnCS7tut+QjN/fTXt8PcvAH+fZKskjwX+jGZI+3Q2Bx4G3Arc15607oAB6n0F2At4M828/HVSVTcB5wPvTvLwJLvTTB0Y68n/CTCveyk9SZI2Bn6xSZI0el9NcgdNb/pfAu8HJryOeVVd1K77APAL4Fus6kX/IPCy9qzw/zRB9TcCv6I5wdx3gFOBk6cLrh2a/iaaxP9nwCuARQPUu4ump35n4F+m235AhwPzaHrfT6eZV39Ou+6L7f+fJrl0grqSJM1IaU4UK0mStP4l+WvgiZ7pXZKktefl4CRJ0lAk2ZZmKLtnfZckaR04VF6SJK13SV5PM/T/zKo6b9TxSJI0kzlUXpIkSZKkHrPHXZIkSZKkHjNxlyRJkiSpxzaqk9Ntt912NW/evFGHIUmSJEnSGvne9753W1XNnmjdRpW4z5s3j0suuWTUYUiSJEmStEaS3DjZOofKS5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPWYibskSZIkST1m4i5JkiRJUo8NNXFPcmCSa5IsS3LsBOsXJFmaZEmSS5LsN2hdSZIkSZI2BUNL3JPMAk4EDgJ2Aw5Pstu4zc4F9qiqPYHXAB9bg7qSJEmSJG30htnjvjewrKquq6p7gNOABd0NqurOqqp2cQugBq0rSZIkSdKmYLMh7nsOcFNneTmwz/iNkhwCvBt4NHDwmtRt6x8FHAUwd+7cdQ5am455x54x6hAmdMNxB0+/kSRJkqRNxjB73DNBWa1WUHV6Ve0KvAT4uzWp29Y/qarmV9X82bNnr22skiRJkiT10jAT9+XATp3lHYEVk21cVecBj0+y3ZrWlSRJkiRpYzXMxP1iYJckOyfZHDgMWNTdIMkTkqS9vRewOfDTQepKkiRJkrQpGNoc96q6L8kxwFnALODkqroyydHt+oXAS4FXJ7kXuAs4tD1Z3YR1hxWrJEmSJEl9NcyT01FVi4HF48oWdm6/B3jPoHUlSZIkSdrUDHOovCRJkiRJWkcm7pIkSZIk9ZiJuyRJkiRJPWbiLkmSJElSj5m4S5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPWYibskSZIkST1m4i5JkiRJUo+ZuEuSJEmS1GMm7pIkSZIk9ZiJuyRJkiRJPWbiLkmSJElSj5m4S5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPWYibskSZIkST1m4i5JkiRJUo+ZuEuSJEmS1GMm7pIkSZIk9ZiJuyRJkiRJPWbiLkmSJElSj5m4S5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPXYUBP3JAcmuSbJsiTHTrD+lUmWtn/nJ9mjs+6GJJcnWZLkkmHGKUmSJElSX202rB0nmQWcCDwfWA5cnGRRVV3V2ex64NlV9bMkBwEnAft01u9fVbcNK0ZJkiRJkvpumD3uewPLquq6qroHOA1Y0N2gqs6vqp+1ixcCOw4xHkmSJEmSZpxhJu5zgJs6y8vbssm8Fjizs1zA2Um+l+SoySolOSrJJUkuufXWW9cpYEmSJEmS+mZoQ+WBTFBWE26Y7E+TuO/XKX5GVa1I8mjgnCRXV9V5q+2w6iSaIfbMnz9/wv1LkiRJkjRTDbPHfTmwU2d5R2DF+I2S7A58DFhQVT8dK6+qFe3/W4DTaYbeS5IkSZK0SRlm4n4xsEuSnZNsDhwGLOpukGQu8C/Aq6rqB53yLZJsNXYbOAC4YoixSpIkSZLUS0MbKl9V9yU5BjgLmAWcXFVXJjm6Xb8Q+GvgUcCHkwDcV1XzgccAp7dlmwGnVtXXhxWrJEmSJEl9Ncw57lTVYmDxuLKFnduvA143Qb3rgD3Gl0uSJEmStKkZ5lB5SZIkSZK0jkzcJUmSJEnqMRN3SZIkSZJ6zMRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckSZIkqcdM3CVJkiRJ6jETd0mSJEmSeszEXZIkSZKkHjNxlyRJkiSpx0zcJUmSJEnqMRN3SZIkSZJ6zMRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckSZIkqcdM3CVJkiRJ6jETd0mSJEmSeszEXZIkSZKkHjNxlyRJkiSpx0zcJUmSJEnqMRN3SZIkSZJ6zMRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckSZIkqcdM3CVJkiRJ6rGhJu5JDkxyTZJlSY6dYP0rkyxt/85PssegdSVJkiRJ2hQMLXFPMgs4ETgI2A04PMlu4za7Hnh2Ve0O/B1w0hrUlSRJkiRpozfMHve9gWVVdV1V3QOcBizoblBV51fVz9rFC4EdB60rSZIkSdKmYJiJ+xzgps7y8rZsMq8FzlzLupIkSZIkbZQ2G+K+M0FZTbhhsj9N4r7fWtQ9CjgKYO7cuWsepSRJkiRJPTbMHvflwE6d5R2BFeM3SrI78DFgQVX9dE3qAlTVSVU1v6rmz549e70ELkmSJElSXwwzcb8Y2CXJzkk2Bw4DFnU3SDIX+BfgVVX1gzWpK0mSJEnSpmBoQ+Wr6r4kxwBnAbOAk6vqyiRHt+sXAn8NPAr4cBKA+9re8wnrDitWSZIkSZL6aphz3KmqxcDicWULO7dfB7xu0LqSJEmSJG1qhjlUXpIkSZIkrSMTd0mSJEmSeszEXZIkSZKkHjNxlyRJkiSpx0zcJUmSJEnqMRN3SZIkSZJ6zMRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckSZIkqcdM3CVJkiRJ6jETd0mSJEmSeszEXZIkSZKkHjNxlyRJkiSpx0zcJUmSJEnqsc2m2yDJFsBdVfVAkicCuwJnVtW9Q49OkjQ08449Y9QhTOqG4w4edQiSJEm9MUiP+3nAw5PMAc4FjgROGWZQkiRJkiSpMUjinqr6NfAHwIeq6hBgt+GGJUmSJEmSYMDEPcm+wCuBsXGV0w6xlyRJkiRJ626QxP0twJ8Dp1fVlUkeB3xjqFFJkiRJkiRggJ7zqvoW8K32JHVU1XXAm4YdmCRJkiRJGqDHPcm+Sa4C/rNd3iPJh4cemSRJkiRJGmio/D8CLwB+ClBVlwHPGmJMkiRJkiSpNUjiTlXdNK7o/iHEIkmSJEmSxhnk7PA3JXk6UEk2p5nf/p/DDUuSJEmSJMFgPe5HA28A5gDLgT3bZUmSJEmSNGSDnFX+NppruEuSJEmSpA1s2sQ9ySeAGl9eVa8ZSkSSJEmSJGmlQea4f61z++HAIcCK4YQjSZIkSZK6Bhkq/+XucpLPAf82tIgkSZIkSdJKA10ObpxdgLnrOxBJkiRJkrS6Qea430Ezxz3t/5uBtw85LkkbuXnHnjHqECZ1w3EHjzoESZIkaaVpe9yraquq2rrz/4njh89PJsmBSa5JsizJsROs3zXJBUnuTvLWcetuSHJ5kiVJLhm8SZIkSZIkbTwm7XFPstdUFavq0qnWJ5kFnAg8n+b67xcnWVRVV3U2ux14E/CSSXazf3s5OkmSJEmSNklTDZV/3xTrCnjuNPveG1hWVdcBJDkNWACsTNyr6hbgliSOS5UkSZIkaQKTJu5Vtf867nsOcFNneTmwzxrUL+DsJAX8c1WdtI7xSJIkSZI04wxyHXeSPBnYjeY67gBU1aemqzZBWQ0eGs+oqhVJHg2ck+TqqjpvgtiOAo4CmDvXk91LkiRJkjYu056cLsk7gA+1f/sD/wD8jwH2vRzYqbO8I7Bi0MCqakX7/xbgdJqh9xNtd1JVza+q+bNnzx5095IkSZIkzQiDXMf9ZcDzgJur6khgD+BhA9S7GNglyc5JNgcOAxYNElSSLZJsNXYbOAC4YpC6kiRJkiRtTAYZKv+bqnogyX1JtgZuAR43XaWqui/JMcBZwCzg5Kq6MsnR7fqFSX4buATYGnggyVtohuRvB5yeZCzGU6vq62vePEmSJEmSZrapLgd3AvA54KIk2wAfBb4H3AlcNMjOq2oxsHhc2cLO7ZtphtCP90uann1JkiRJkjZpU/W4/xA4HtiBJln/HM012beuqqUbIDZJkiRJkjZ5k85xr6oPVtW+wLOA24FPAGcCL0myywaKT5IkSZKkTdq0J6erqhur6j1V9bvAK4BDgKuHHpkkSZIkSRrocnAPTfLiJJ+l6XH/AfDSoUcmSZIkSZKmPDnd84HDgYNpTkZ3GnBUVf1qA8UmSZIkSdImb6qT0/0FcCrw1qq6fQPFI0mSJEmSOiZN3Ktq/w0ZiCRJkiRJWt20c9wlSZIkSdLomLhLkiRJktRjJu6SJEmSJPWYibskSZIkST1m4i5JkiRJUo+ZuEuSJEmS1GMm7pIkSZIk9ZiJuyRJkiRJPWbiLkmSJElSj5m4S5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPWYibskSZIkST1m4i5JkiRJUo9tNuoAJGmmmnfsGaMOYVI3HHfwqEOQJEnSemKPuyRJkiRJPWbiLkmSJElSj5m4S5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPWYibskSZIkST021MQ9yYFJrkmyLMmxE6zfNckFSe5O8tY1qStJkiRJ0qZgaIl7klnAicBBwG7A4Ul2G7fZ7cCbgOPXoq4kSZIkSRu9Yfa47w0sq6rrquoe4DRgQXeDqrqlqi4G7l3TupIkSZIkbQqGmbjPAW7qLC9vy4ZdV5IkSZKkjcYwE/dMUFbru26So5JckuSSW2+9deDgJEmSJEmaCYaZuC8Hduos7wisWN91q+qkqppfVfNnz569VoFKkiRJktRXmw1x3xcDuyTZGfgRcBjwig1QV5KkGWHesWeMOoRJ3XDcwaMOQZIktYaWuFfVfUmOAc4CZgEnV9WVSY5u1y9M8tvAJcDWwANJ3gLsVlW/nKjusGKVJEmSJKmvhtnjTlUtBhaPK1vYuX0zzTD4gepKkiRJkrSpGWriro2XwzslSZIkacMY5snpJEmSJEnSOjJxlyRJkiSpx0zcJUmSJEnqMRN3SZIkSZJ6zMRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckSZIkqcdM3CVJkiRJ6jETd0mSJEmSeszEXZIkSZKkHjNxlyRJkiSpx0zcJUmSJEnqMRN3SZIkSZJ6zMRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckSZIkqcdM3CVJkiRJ6jETd0mSJEmSeszEXZIkSZKkHjNxlyRJkiSpx0zcJUmSJEnqMRN3SZIkSZJ6zMRdkiRJkqQeM3GXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4bauKe5MAk1yRZluTYCdYnyT+165cm2auz7oYklydZkuSSYcYpSZIkSVJfbTasHSeZBZwIPB9YDlycZFFVXdXZ7CBgl/ZvH+Aj7f8x+1fVbcOKUZIkSZKkvhtmj/vewLKquq6q7gFOAxaM22YB8KlqXAhsk2T7IcYkSZIkSdKMMszEfQ5wU2d5eVs26DYFnJ3ke0mOGlqUkiRJkiT12NCGygOZoKzWYJtnVNWKJI8GzklydVWdt9qdNEn9UQBz585dl3glSZIkSeqdYfa4Lwd26izvCKwYdJuqGvt/C3A6zdD71VTVSVU1v6rmz549ez2FLkmSJElSPwwzcb8Y2CXJzkk2Bw4DFo3bZhHw6vbs8r8H/KKqfpxkiyRbASTZAjgAuGKIsUqSJEmS1EtDGypfVfclOQY4C5gFnFxVVyY5ul2/EFgMvBBYBvwaOLKt/hjg9CRjMZ5aVV8fVqySJEmSJPXVMOe4U1WLaZLzbtnCzu0C3jBBveuAPYYZmyRJkiRJM8Ewh8pLkiRJkqR1ZOIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPWYibskSZIkST1m4i5JkiRJUo+ZuEuSJEmS1GMm7pIkSZIk9ZiJuyRJkiRJPWbiLkmSJElSj5m4S5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjJu6SJEmSJPWYibskSZIkST1m4i5JkiRJUo+ZuEuSJEmS1GMm7pIkSZIk9ZiJuyRJkiRJPWbiLkmSJElSj5m4S5IkSZLUYybukiRJkiT1mIm7JEmSJEk9ZuIuSZIkSVKPmbhLkiRJktRjm406AEmSJElaW/OOPWPUIUzqhuMOHnUI2kiYuEuSpE2WP/glSTOBibskSZK0Dvp6AMiDP9LGwznukiRJkiT1mIm7JEmSJEk95lD5EXFIlSRJkiRpECbukqQZq68HQcEDoZIkaf0ZauKe5EDgg8As4GNVddy49WnXvxD4NXBEVV06SF1JkiT19wCWB6+kwfX1fQy+l/tiaHPck8wCTgQOAnYDDk+y27jNDgJ2af+OAj6yBnUlSZIkSdroDbPHfW9gWVVdB5DkNGABcFVnmwXAp6qqgAuTbJNke2DeAHUlSdKI9bWXyB4iSdpw+vpdABvP98EwE/c5wE2d5eXAPgNsM2fAutImzQ9ISdLGwO8zSZpems7uIew4eTnwgqp6Xbv8KmDvqnpjZ5szgHdX1Xfa5XOB/wM8brq6nX0cRTPMHuBJwDVDaVC/bQfcNuog1tFMb4Pxj95Mb8NMjx9mfhtmevww89sw0+OHmd8G4x+9md6GmR4/zPw2zPT4YeNow9p4bFXNnmjFMHvclwM7dZZ3BFYMuM3mA9QFoKpOAk5a12BnsiSXVNX8UcexLmZ6G4x/9GZ6G2Z6/DDz2zDT44eZ34aZHj/M/DYY/+jN9DbM9Phh5rdhpscPG0cb1rehnZwOuBjYJcnOSTYHDgMWjdtmEfDqNH4P+EVV/XjAupIkSZIkbfSG1uNeVfclOQY4i+aSbidX1ZVJjm7XLwQW01wKbhnN5eCOnKrusGKVJEmSJKmvhnod96paTJOcd8sWdm4X8IZB62pSG8NUgZneBuMfvZnehpkeP8z8Nsz0+GHmt2Gmxw8zvw3GP3ozvQ0zPX6Y+W2Y6fHDxtGG9WpoJ6eTJEmSJEnrbphz3CVJkiRJ0joyce+5JPcnWdL5m9eW753km0l+mOTSJGckecq4upcl+dxIAp9EkocnuaiN7cokf9OWn5Lk+raNlybZd9SxjlmbmJN8MMmPkvTmPTbBa+nIzu17klze3j6u3f5Pk/wmySN7EPuOSf61fb1f2z6+myd5TpJfJPl+kquTHN+pc0SSW9s2XZnkS0n+24jiv78Tx2VJ/mzstTFT2tDGc0iSSrJru/yQJP+U5Ir29XNxe1LR77Yx/1cn/pWfX6OU5C/bx3JpG9M32v/L2udhLNant5+xvTmjbed1dFn7mfP0tnxekism2P6UJC9rb2/bvsaO3NBxt/f/qM5je3P7+Ti2PHeS9/e8JMvHf462dfYeRTvG6zwnVyT54tj7c4LP23kjDnWlCWKeM8Vzs/kE75l9Rt2GQSTZN8lHN9B9nT/N+te0n5FL28d9QVt+RJId1uL+XpJkt7WNt7Of6eK+oRP3t5I8dl3vc4L7WPk5pcFM8PlybFv+zSTXdMrHPv8fk+TUJNcl+V6SC5IcMtpWaK1UlX89/gPunKDsMcANwNM7ZfsBL+ks/w5wOfAjYItRt6MTV4At29sPBb4L/B5wCvCytvwAYOmoY13bmGkOiP0XcCHwnFHHP9VrqbPuBmC7cWUXAd8GjujB438RcGS7PAv4OPBe4DnA19ryRwBXA89ol48ATujs59SxfYzysQceDfwb8Dft8oxoQ3v/X2hfE+9slw8HvgQ8pF3eEfitzvYPin/Uf8C+wAXAw9rl7YAdxj8Pne2/CcwfddyTvI5eAHyrvT0PuGKC7U8BXgY8kuZqLX8y6ja0cb0TeGt7e9L3d7t8AfDsTt1dgWtH3YZJnpPPAn82vrxvf5PFPP65aZcnfc/05a99754yQfnfAC/tQXw7AtcCj2yXtwR2bm+v8WcMzfmpTqH9/bEm9dYi9htofxu0j+dHh/D4TNsWoIBPd9q/GXArq747j2iXlwBXAa8f9fO+rm2epv6Eny8TvZ7az9gLgKM7ZY8F3rie2/So9vFfAtxMk3+MLc8F/hX4Yfte+CCw+Xq4z22A/9VZ3gH40qif32H+9aY3UGvkGOCTVbXySGlVfaeqvtLZ5hXAp4Gzgf+xYcObXDXubBcf2v6NP9HCecATNmhgU1iLmPcHrgA+QpPYzDhJHk/z4+KvGH0bngv8pqo+AVBV9wN/CrwGWNn7XFV30XxBzBm/gySbAVsAP9sA8U6pqm4BjgKOSZJx63rbhiRbAs8AXktziU6A7YEfV9UDAFW1vKpG/hhPYXvgtqq6G6CqbquqFSOOaW1tzWCvhS2BM4FTq+ojww1prUz6/m57rz/Hqtcb7e1ejSTr+DY9+u4a0HQxz+T3zPNoDpIOXZI72//bJzmvM6LhmTQHa+8A7gSoqjur6vq2N3Q+8Nl2+0ck+es0I5euSHLS2HdE25P6riTfAt5O87vuvW29x7d/X297U7+dVaOiTkny/iTfAN6zhnGPdwHtd1OS2Um+3MZ6cZJndMrPSTMi6J+T3Jhku4wbFZTkrUneOUE8E7YfeAB4fpJvA28Gnk+TGHZ9vqr2pDmQ864kj5nqOduEPBe4px58cvAbq+pD6/NOquqnVbVn+xwsBD7Q3v5dmgP8X6mqXYAn0nwv/f0g+21/+0xmG+B/dWJYUVUb9egNE/f+e0RnyMvpbdl/By6dpt6hwOdpfuCMOvF6kCSzkiwBbgHOqarvjtvkxTSjBXpjDWM+nOZxPx14UZKHbrBApzbRa2kyY234NvCkJI8efniT+u/A97oFVfVLmlENK39wJvktYBeagyhjDm2ftx8B2wJfHXawg6iq62g+fx/0uPa8DS8Bvl5VPwBuT7IXTQ/8i9vX1PuS/O6IYhvU2cBOSX6Q5MNJnj3qgNbQ2Hv4auBjwN8NUOf9wHeq6gPDDW2tTff+/gLwks6Pt0OB0zZohANo4zuIVd8Da/J5OxITxDyRGfmeSbIdcG9V/WID3/UrgLPahGUPmgOxlwE/Aa5P8okkLwaoqi8BlwCvbBOeu2hGKD2tqp5MMwLrRZ19b1NVz66qvwcWAW9r611Lc/btN1bVU4G3Ah/u1Hsi8PtV9b/XMO7xDgS+0t7+IE1i9jTgpTSfRwDvAP69qvai+Q00d4r7nMhU7f8R8MGqeh+rfqOspj04fi1Nr/Jqkjy78978fpKt2vK3tQcNlqadEtmWv7otuyzJp9uyxyY5ty0/N8nctvyUNNPHzk8zLH1sqHqSnJDkqiRn0PnuT3JcW740naly0+h+vixJcmhn3Wc75Y9isJxhmKY7OLuaNFNIvpjkq8DZSbZsH+dL00zdWNBuehzw+Lat7+0eIEozzfUT7fbfT7L/8Js6fEO9HJzWi7vaD9JJJfkuTe/L2VX15iRPA26tqhuTLAdOTvJbfekJa9+0eybZBjg9yZPbVe9N8lc0w51eO6r4JjJozEk2B14I/GlV3dE+NwcAZ4wi7nGmfS11HAYcUlUPJPkX4OXAiUOLbGph9REO3fJnJlkKPAk4rqpu7mzz+aoa69k+EXgbzQd9H3R722dCGw4H/rG9fRpweFW9LcmTaL6Ynwucm+TlVXXuCOKbVlXdmeSpwDNpRsZ8PsmxVXXKaCMb2Mr3cJpzanyq81k0mX8HFiQ5vv1B2zdTvr+r6uYkVwLPS/ITmmRstfn8I/SI9sAaNAc6P97eXpPP2w1tsphX0+f3TPv9+jCa3rttO216O82w3bNHENbFNL+5HkrTw7gEIMmBwNNoRgF8IMlTq+qdE9TfP8n/oRlNti1wJasO1n5+ojtMMxrq6cAXs2oQ18M6m3yx/Q2zxnG3vpGm9/oWmlF4AL8P7Na5v63bBHg/4BCAqvp6kjX93TlV+08ADkvyNWB34GSa1+WDJHkc8Dhg2ST38VbgDVX1H+1j95skB9AcNN+b5rNnUZJnAT8F/pJm+tptSbbtxPKpqvpkktcA/0RzcBuaUSr70UzrWUTT23wIzff7U2imu15F83hv267btaqq/Y05iKk+X15ZVZd0Ho8HrUxyYhvfPe2Bl2Gb8OBskrGDs0snqbcvsHtV3Z7mIOMhbb3tgAuTLAKOBZ7c+V6c16n/hva+npJmBMrZSZ5YVb9Zj23b4Oxxn5muBPYaW6iqfYD/SzOPEZof2LsmuYHmqOPWNEdEe6Wqfk4zH+fAtmjs6PHze/bDbKUBYj6Q5nm4vH3896NnIx6mk2R3mi+wc9o2HMZo23AlzXDClZJsDexE8/r+dlXtTvOF+CdJ9hy/g6oqmi//Zw092gG0Pyzup/khBD1vQ3vU/rnAx9rXxNtoRgKkqu6uqjOr6m3Au1j146WXqur+qvpmVb2DZtpR7z4bB1FVF9DMN549zaan0UzbWdz+sO6b6d7fsGq4fB+Hyd81Njy0qt5YVfeMOqABrFHMfX3PVNU+7Q/21wGLOm06i2YkwdcB2l63JUkWb4CYzqP5jP4R8Okkr27Lq6ouqqp307yOV3sMkzycpqf8ZVX1FOCjwMM7m/xqkrt9CPDzTvv3rKrfGaDetHG39qfpvb4S+NvOfe7bub85VXUHDz4g3XUfD845Hj5+gwHafznN+TwOByZ6LsdGp30O+OOqun2SWP4DeH+SN9GMYriPpoPlAOD7NL3Tu9L8DnouzZzp2wA6+9yX5pwz0ExL3a+z/69U1QNVdRVNkg7NY/u59r20guaAKsAvgd/QfLf+AfDrSWJeF+NzhjfQHECa7rtjfZmu82Uy53Qe79BMf1hKM/1lDqse28nsR/PcUFVXAzfSjD6Z0UzcZ6YTgSPSnlG4NXYm24fQ9I7uXlXzqmoesICeJI9p5j9t095+BM1R26tHGtQ01jDmw4HXdR77nYEDJhsO1FOH05x8bF77twMwJ0M4m+yAzgX+29gPiSSzgPfRnNxl5ZdcNUO4303T2zKR/ViVCIxMktk0879OaJPxlXrchpfR9C48tn1N7ARcDzwr7RmR28+e3Wm+HHspyZOS7NIp2pMexzuVtgdhFk2P0JSq6h9p3kent6OC+mTS93dVjb2/v0wzkqmXw+Q3ZjPxPdOOTtqddrh3VR3ZJpcv3AD3/Vjglqr6KM1Ihr2S7JBmatGYPVn1GN4BjB1QG0tSb2t7gqeaq7uyXjVTS65P8vI2hiTZY13j7q6vZhj/W4BXt73EZ9McxBmrv2d78zvA/2zLDgB+qy3/CfDoNFeXeBgPHgI/ZpD2LwKOZ+IDeJ9vn+d9qmrS6SlVdRzNwZ5H0PTc7kqTGL67cyDiCVX1caZPLlfutnP77s7tTLLNWCz30fTyf5l2OtoA97Wm/h14eJI/6ZRtyN+kgxycnUj3gNMraQ40PLU9WPcTJjj4M85kB5FmNBP3GaiaYbSHAu9Ocwmj82k+4E6gPWJaVd2TdpxHM6Rp+w0f7Wq2pxl2tZRmaNY5VfW1Ecc0nYFibpPzF9AZFl9Vv6L5InvxBop1fTiMZm5a1+k8+ARRG0yb3B4CvDzJD4Ef0Byh/osJNl9Ik0zu3C4f2va0LKU5Qcogc4KHYWw+2pU0R4vPpjlD70T62IbDWf018WWagydfTTOnbClNr8oJGza0NbIl8Mm08wmB3WjOoj2VM9Jckmx5ki8OPcKprZzXSDNs9o86Q2Cf1Ilz+diP+DFV9XbgJpretN589w/y/m5HOl0I/KSqrh9FnJuwtXnPjNpTge+PPzC6gTwHWJLk+zS96h+kOaHt8Wku97mE5vfbm9vtTwEWtuV30/QyX04zl/ziKe7nNOBtaebuPp4msXltkstoEqUFU9QdNO4Hqaof0yTMbwDeBMxPMy/7KuDodrO/oemsuJRm1MOPgTuq6l6a3vrvAl9jgs6P9n0+XftPBv62qtb6PEhJHl9Vl1fVe2jOMbArcBbNnOst223mpDm3z7nA/2xHnZFVQ+XPZ9VvolfS/M6bynk0w/xntb/F92/3tyXN1QYW0xwY2XPAZoyf4z7p9Ln2ffAS4NlpLmF8EfBJJu8gWN8GOTg7nUfSHFi6N81c9bGOpO6Br/HOo3luSPJEmvMtXLN2TeiPjOZzTZIkSVq/0px3ZllVOTpjA2t70++vqvvSnIfjI7UezvWQ5M6q2nJc2XNoLl34oiRH0FwG7ZgJqo/f14doEuf7aeaaH1FVdyd5M01PPDRXAPjDqro2yR/RTA+7n+aA0BFp5lKfTDNd6Vaay1n+V5JTaC5R96Vu3O0okA/RDL3/QXsfn6EZtv+vNL3HAY6vqk+u8QPUM2muGHBnVR3fLu9EMw1iV5pO48U0z93dk9Q/gs7zmWZe+1dpDoItobnCzUFVdUOSU2lG2JxJMyL5a1X15DRTLxbSHMi7j+ayl98YSoM3IBN3SZIkSeuknVbxBZrk7B6aa2xPNXJA0howcZckSZIkqce8HJwkSZKkjUaSI1l1LoEx/9GeVV09kOQFwHvGFV9fVYeMIp6ZwB53SZIkSZJ6rDdnlpUkSZIkSaszcZckSZIkqcdM3CVJ2oQlubNz+4VJfphk7ihjkiRJD+bJ6SRJEkmeR3Ot4QOq6r9GHY8kSVrFHndJkjZxSZ4JfBQ4uKqubcv+MMlFSZYk+ecks5K8NskHOvVen+T9SbZIckaSy5JckeTQUbVFkqSNkWeVlyRpE5bkXuAO4DlVtbQt+x3gH4A/qKp7k3wYuBD4MrAU2LUtPx/4Y+CJwIFV9fq2/iOr6hcjaI4kSRsle9wlSdq03QucD7y2U/Y84KnAxUmWtMuPq6pfAf8OvCjJrsBDq+py4HLg95O8J8kzTdolSVq/7HGXJGkT1p6c7tHAvwFfq6p3JXkjsENV/fkE2+8D/AVwNXBjVX24Ld8WeCFwNHB2Vf3thmqDJEkbO09OJ0nSJq6qfp3kRcC3k/wEOBf41yQfqKpb2qR8q6q6saq+m2QnYC9gd4AkOwC3V9Vn2gMBR4yoKZIkbZRM3CVJElV1e5IDgfOAtwB/BZyd5CE0w+nfANzYbv4FYM+q+lm7/BTgvUkeaLf9kw0ZuyRJGzuHykuSpDWS5GvAB6rq3FHHIknSpsCT00mSpIEk2SbJD4C7TNolSdpw7HGXJEmSJKnH7HGXJEmSJKnHTNwlSZIkSeoxE3dJkiRJknrMxF2SJEmSpB4zcZckSZIkqcdM3CVJkiRJ6rH/D2stIJOu/QYNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 50, 'maxDepth': 9, 'maxBins': 64, 'impurity': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:33:09 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.649229016532429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:34:33 WARN DAGScheduler: Broadcasting large task binary with size 1089.0 KiB\n",
      "23/12/11 12:34:51 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/11 12:35:05 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/12/11 12:35:21 WARN DAGScheduler: Broadcasting large task binary with size 1182.4 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 50, 'maxDepth': 9, 'maxBins': 64, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:35:24 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6512955701568461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 50, 'maxDepth': 6, 'maxBins': 32, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6365647520135651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 50, 'maxDepth': 6, 'maxBins': 64, 'impurity': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6326568461212378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 25, 'maxDepth': 6, 'maxBins': 64, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6362733149639678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:39:26 WARN DAGScheduler: Broadcasting large task binary with size 1102.9 KiB\n",
      "23/12/11 12:39:30 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameters {'numTrees': 25, 'maxDepth': 9, 'maxBins': 16, 'impurity': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:39:37 WARN DAGScheduler: Broadcasting large task binary with size 1401.5 KiB\n",
      "[Stage 636:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.6511895930479017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# random search\n",
    "hyperparameters = {\n",
    "    'numTrees': [25, 50],\n",
    "    'maxDepth': [6, 9],\n",
    "    'maxBins' : [16, 32, 64],\n",
    "    'impurity' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "number_of_combinations = 12\n",
    "random_combinations = random.sample(list(itertools.product(*hyperparameters.values())), number_of_combinations)\n",
    "\n",
    "for combo in random_combinations:\n",
    "    param_dict = dict(zip(hyperparameters.keys(), combo))\n",
    "    \n",
    "    rf = RandomForestClassifier(labelCol=\"PosNum\", featuresCol=\"features_scaled\", numTrees=param_dict['numTrees'], impurity=param_dict['impurity'], maxDepth=param_dict['maxDepth'], maxBins=param_dict['maxBins'])\n",
    "\n",
    "    rf = rf.fit(trainingData)\n",
    "\n",
    "    importance = {}\n",
    "    featureImportances = list(rf.featureImportances)\n",
    "\n",
    "    for i,e in enumerate(featureImportances):\n",
    "        importance[num_col[i]] = e\n",
    "    \n",
    "    plot_importance(importance)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = rf.transform(valData)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"PosNum\"\n",
    "                                                , predictionCol=\"prediction\"\n",
    "                                                , metricName=\"accuracy\")\n",
    "\n",
    "    print('With parameters', param_dict)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print('Validation accuracy =', accuracy)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16c9f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/11 12:44:09 WARN DAGScheduler: Broadcasting large task binary with size 1086.4 KiB\n",
      "23/12/11 12:44:20 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/12/11 12:44:33 WARN DAGScheduler: Broadcasting large task binary with size 3.9 MiB\n",
      "23/12/11 12:44:51 WARN DAGScheduler: Broadcasting large task binary with size 1188.1 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"PosNum\", featuresCol=\"features_scaled\", numTrees= 50, maxDepth= 9, maxBins= 16, impurity= 'gini')\n",
    "\n",
    "rf = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9c152b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(18, {0: 0.0092, 1: 0.0516, 2: 0.257, 3: 0.0015, 4: 0.1672, 5: 0.1381, 6: 0.2225, 7: 0.0047, 8: 0.098, 9: 0.0039, 10: 0.0094, 11: 0.0045, 12: 0.0012, 13: 0.0128, 14: 0.0002, 15: 0.0119, 16: 0.0043, 17: 0.0022})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edaf489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FGA': 0.009237997544972452,\n",
       " '3P': 0.051609774403026075,\n",
       " '3PA': 0.25697149981138984,\n",
       " 'FTA': 0.0014945294185306419,\n",
       " 'ORB': 0.16717734526704775,\n",
       " 'DRB': 0.13806838110516315,\n",
       " 'AST': 0.22248069846899515,\n",
       " 'STL': 0.0046589720109432835,\n",
       " 'BLK': 0.09800856367816921,\n",
       " 'TOV': 0.00387402289810345,\n",
       " 'PF': 0.009369542376732959,\n",
       " 'PTS': 0.004476833826556965,\n",
       " '+/-': 0.0011808223256914634,\n",
       " 'isStarter': 0.01281010679629582,\n",
       " 'isRegular': 0.00020585026255113984,\n",
       " 'MP_seconds': 0.011886780962158618,\n",
       " 'EFG': 0.004337094499766828,\n",
       " 'TO_ratio': 0.002151184343905236}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/12 15:54:48 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 33356602 ms exceeds timeout 120000 ms\n",
      "23/12/12 15:54:49 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/12/12 15:54:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/12 15:54:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/12 15:54:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:54:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:54:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:54:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:55:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:56:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:57:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:58:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 15:59:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:00:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:01:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:02:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:03:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:04:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:04:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:04:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:04:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:04:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:04:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.121:54034\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/12 16:04:24 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "importance = {}\n",
    "featureImportances = list(rf.featureImportances)\n",
    "\n",
    "for i,e in enumerate(featureImportances):\n",
    "    importance[num_col[i]] = e\n",
    "\n",
    "importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
